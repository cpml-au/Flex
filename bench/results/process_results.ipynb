{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['678_visualizing_environmental.csv', '687_sleuth_ex1605.csv', '659_sleuth_ex1714.csv', '561_cpu.csv', 'alpinegp-blackbox_results.csv', '1029_LEV.csv', '522_pm10.csv', '542_pollution.csv', '1027_ESL.csv', '695_chatfield_4.csv', '229_pwLinear.csv', '712_chscase_geyser1.csv', '547_no2.csv', '1096_FacultySalaries.csv', '666_rmftsa_ladata.csv', '192_vineyard.csv', '519_vinnie.csv', '527_analcatdata_election2000.csv', '195_auto_price.csv', '706_sleuth_case1202.csv', '523_analcatdata_neavote.csv', '560_bodyfat.csv', '485_analcatdata_vehicle.csv', '556_analcatdata_apnea2.csv', '690_visualizing_galaxy.csv', '663_rabe_266.csv', '557_analcatdata_apnea1.csv', '665_sleuth_case2002.csv', '210_cloud.csv', '1089_USCrime.csv', '230_machine_cpu.csv', '228_elusage.csv']\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "extension = 'csv'\n",
    "result_files = glob.glob('*.{}'.format(extension))\n",
    "print(result_files)\n",
    "print(len(result_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87081/2928257638.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  aggregated_results = pd.concat([aggregated_results, data])\n"
     ]
    }
   ],
   "source": [
    "r2_tests= []\n",
    "aggregated_results = pd.DataFrame()\n",
    "# combine all the results files into one dataset\n",
    "for file in result_files: \n",
    "    # skip aggregate results file\n",
    "    if \"_results\" in file:\n",
    "        continue\n",
    "    # skip Friedman datasets\n",
    "    if \"fri\" in file:\n",
    "        continue\n",
    "    data = pd.read_csv(file, sep=\";\", header=0)\n",
    "    aggregated_results = pd.concat([aggregated_results, data])\n",
    "    r2_tests.append(data[\"r2_test\"].to_numpy())\n",
    "\n",
    "# add algorithm name\n",
    "aggregated_results[\"algorithm\"] = \"AlpineGP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   algorithm                        problem   r2_test\n",
      "0   AlpineGP  678_visualizing_environmental  0.204556\n",
      "1   AlpineGP  678_visualizing_environmental  0.408901\n",
      "2   AlpineGP  678_visualizing_environmental  0.226601\n",
      "3   AlpineGP  678_visualizing_environmental  0.227555\n",
      "4   AlpineGP  678_visualizing_environmental -0.109123\n",
      "..       ...                            ...       ...\n",
      "5   AlpineGP                    228_elusage  0.701418\n",
      "6   AlpineGP                    228_elusage  0.825378\n",
      "7   AlpineGP                    228_elusage  0.762651\n",
      "8   AlpineGP                    228_elusage  0.785289\n",
      "9   AlpineGP                    228_elusage  0.527974\n",
      "\n",
      "[300 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(aggregated_results[[\"algorithm\", \"problem\", \"r2_test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results = aggregated_results.rename(columns={\"r2_test\": \"r2_zero_test\", \"problem\": \"dataset\"})\n",
    "\n",
    "aggregated_results.to_csv(\"alpinegp-blackbox_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          dataset  r2_train  r2_zero_test  r2_difference\n",
      "0         485_analcatdata_vehicle  0.804305      0.397549       0.406756\n",
      "1                   542_pollution  0.679228      0.355834       0.323394\n",
      "2                    192_vineyard  0.800718      0.477841       0.322876\n",
      "3               659_sleuth_ex1714  0.899852      0.587538       0.312315\n",
      "4               687_sleuth_ex1605  0.733993      0.433322       0.300671\n",
      "5                    1089_USCrime  0.875139      0.600101       0.275039\n",
      "6                       210_cloud  0.889730      0.731848       0.157882\n",
      "7   678_visualizing_environmental  0.433137      0.278718       0.154419\n",
      "8             706_sleuth_case1202  0.764207      0.631445       0.132763\n",
      "9                     228_elusage  0.856486      0.763533       0.092953\n",
      "10           1096_FacultySalaries  0.894071      0.809196       0.084875\n",
      "11                       522_pm10  0.232981      0.149032       0.083949\n",
      "12                230_machine_cpu  0.911400      0.828245       0.083155\n",
      "13            665_sleuth_case2002  0.413762      0.348861       0.064902\n",
      "14                   229_pwLinear  0.704544      0.645193       0.059351\n",
      "15                        561_cpu  0.963911      0.914378       0.049534\n",
      "16                        547_no2  0.482919      0.453533       0.029385\n",
      "17                       1029_LEV  0.561614      0.533544       0.028070\n",
      "18                     519_vinnie  0.757825      0.732460       0.025365\n",
      "19            712_chscase_geyser1  0.771483      0.756233       0.015250\n",
      "20        523_analcatdata_neavote  0.952758      0.943564       0.009193\n",
      "21                695_chatfield_4  0.875092      0.869436       0.005656\n",
      "22   527_analcatdata_election2000  0.995035      0.991528       0.003507\n",
      "23         690_visualizing_galaxy  0.958505      0.955321       0.003184\n",
      "24                   663_rabe_266  0.989899      0.989354       0.000544\n",
      "25                       1027_ESL  0.858720      0.864982      -0.006262\n",
      "26         556_analcatdata_apnea2  0.793689      0.815028      -0.021339\n",
      "27                    560_bodyfat  0.968663      0.997511      -0.028847\n",
      "28         557_analcatdata_apnea1  0.814794      0.853373      -0.038580\n",
      "29              666_rmftsa_ladata  0.621472      0.660772      -0.039300\n"
     ]
    }
   ],
   "source": [
    "# Group by problem and calculate the mean, median, and standard deviation for r2_zero_test scores\n",
    "algorithm_stats = aggregated_results.groupby(\"dataset\").agg({\"r2_train\": \"median\", \"r2_zero_test\": \"median\"}).reset_index()\n",
    "\n",
    "algorithm_stats[\"r2_difference\"] = algorithm_stats[\"r2_train\"] - algorithm_stats[\"r2_zero_test\"]\n",
    "\n",
    "# Sort algorithms by median r2_zero_test score\n",
    "algorithm_stats = algorithm_stats.sort_values(by=\"r2_difference\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(algorithm_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          dataset      mean    median       std\n",
      "0                     560_bodyfat  0.995082  0.997511  0.005727\n",
      "1    527_analcatdata_election2000  0.989987  0.991528  0.005610\n",
      "2                    663_rabe_266  0.986026  0.989354  0.011057\n",
      "3          690_visualizing_galaxy  0.955560  0.955321  0.007762\n",
      "4         523_analcatdata_neavote  0.936344  0.943564  0.028017\n",
      "5                         561_cpu  0.868028  0.914378  0.122736\n",
      "6                 695_chatfield_4  0.868838  0.869436  0.040004\n",
      "7                        1027_ESL  0.858704  0.864982  0.022962\n",
      "8          557_analcatdata_apnea1  0.842992  0.853373  0.053027\n",
      "9                 230_machine_cpu  0.682516  0.828245  0.315859\n",
      "10         556_analcatdata_apnea2  0.813277  0.815028  0.034472\n",
      "11           1096_FacultySalaries  0.629100  0.809196  0.491015\n",
      "12                    228_elusage  0.718989  0.763533  0.093993\n",
      "13            712_chscase_geyser1  0.758240  0.756233  0.039447\n",
      "14                     519_vinnie  0.735402  0.732460  0.036598\n",
      "15                      210_cloud  0.770488  0.731848  0.106019\n",
      "16              666_rmftsa_ladata  0.648221  0.660772  0.035994\n",
      "17                   229_pwLinear  0.625295  0.645193  0.066138\n",
      "18            706_sleuth_case1202  0.559768  0.631445  0.266130\n",
      "19                   1089_USCrime  0.625445  0.600101  0.131137\n",
      "20              659_sleuth_ex1714  0.552759  0.587538  0.252955\n",
      "21                       1029_LEV  0.541604  0.533544  0.043504\n",
      "22                   192_vineyard  0.349031  0.477841  0.435225\n",
      "23                        547_no2  0.442686  0.453533  0.097810\n",
      "24              687_sleuth_ex1605  0.189029  0.433322  0.496445\n",
      "25        485_analcatdata_vehicle  0.126240  0.397549  0.589762\n",
      "26                  542_pollution  0.277189  0.355834  0.364377\n",
      "27            665_sleuth_case2002  0.351240  0.348861  0.104693\n",
      "28  678_visualizing_environmental  0.276808  0.278718  0.169048\n",
      "29                       522_pm10  0.163662  0.149032  0.074717\n"
     ]
    }
   ],
   "source": [
    "# Group by problem and calculate the mean, median, and standard deviation for r2_zero_test scores\n",
    "algorithm_stats = aggregated_results.groupby(\"dataset\")[\"r2_zero_test\"].agg(['mean', 'median', 'std']).reset_index()\n",
    "\n",
    "# Sort algorithms by median r2_zero_test score\n",
    "algorithm_stats = algorithm_stats.sort_values(by=\"median\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(algorithm_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_tests = np.concatenate(r2_tests).ravel()\n",
    "# print(r2_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test R2 =  0.6379516825728591\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean test R2 = \", r2_tests.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33572567067609765"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_tests.std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median test R2 =  0.7097814872317425\n"
     ]
    }
   ],
   "source": [
    "print(\"Median test R2 = \", np.median(r2_tests).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
